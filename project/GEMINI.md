###  LLM Prompt

**Persona:** You are an expert in graph machine learning and Python, specializing in PyTorch Geometric, NetworkX, and Scikit-learn. You are a helpful assistant tasked with helping a university student complete a project. Your goal is to provide clear, actionable, and high-quality Python code that integrates seamlessly into an existing project structure.

**Context:** I am working on a network science course project with two other students. The project has three main tasks: Link Prediction, Community Detection, and Role Discovery. My assigned task is **Role Discovery**. The individual parts of the project are due on July 1st.

I have also conducted extensive research on **Role Discovery**, and I am providing my detailed research notes. Key takeaways from my research are:
1.  **Goal:** Group nodes by structural equivalence, not connectivity (vs. Community Detection).
2.  **Traditional Method:** Involves extracting structural features (e.g., centrality, clustering coefficient) for each node and then using a clustering algorithm like K-Means on these features.
3.  **Deep Learning (GNN) Method:** Involves using an unsupervised GNN model, like a **Graph Autoencoder (GAE)**, to learn low-dimensional node embeddings. These embeddings are then clustered using K-Means.
4.  **Evaluation:** Since role discovery is unsupervised, evaluation must use internal clustering metrics like the **Silhouette Score**, **Davies-Bouldin Index**, and **Calinski-Harabasz Index**. Qualitative evaluation via **t-SNE or UMAP visualization** is also crucial.


**Deep Research:**
A Comprehensive Research Study on Role Discovery in GraphsPart 1: Conceptual Foundations of Role DiscoveryThis section establishes the foundational theory of role discovery. A firm grasp of these concepts is essential for understanding the methodologies, justifying experimental choices, and interpreting the results of the subsequent analysis. It differentiates role discovery from the related but distinct task of community detection and provides a taxonomy of common roles observed in network analysis.1.1 Defining Roles: The Principle of Structural EquivalenceRole discovery, at its core, is the task of identifying and grouping nodes within a network that exhibit similar structural behaviors or patterns of connectivity.1 The guiding principle behind this task is the concept of structural equivalence. In its strictest form, rooted in classical social network analysis, two nodes are considered structurally equivalent if they are connected to the exact same set of other nodes.3 For a directed graph, this means they must share the same set of incoming neighbors and the same set of outgoing neighbors.4 This formalizes the idea of a relational "niche" or "position" within the network structure. The intuition is that nodes occupying the same structural position are subject to similar network forces and constraints, and thus are expected to develop similar characteristics or perform similar functions.4However, this definition of perfect equivalence is exceedingly rigid and rarely observed in real-world networks.4 Consequently, modern approaches to role discovery have relaxed this constraint, instead seeking to identify groups of nodes that are approximately structurally equivalent. These methods aim to automatically discover underlying roles—such as "clique-members," "periphery-nodes," or "bridges"—directly from the graph data, often without any prior knowledge of what roles might exist.1 The goal is to partition the nodes into a set of classes where nodes within a given class have similar patterns of connections to nodes in other classes. This shift from verifying perfect equivalence to discovering approximate equivalence recasts role discovery as an unsupervised machine learning problem, where the objective is to learn a meaningful grouping of nodes based on their structural features.1.2 Role Discovery vs. Community Detection: A Critical DistinctionA frequent point of confusion in network science is the distinction between role discovery and community detection. While both tasks involve grouping nodes, they operate on fundamentally different principles and reveal distinct aspects of a network's organization.6Community Detection is concerned with finding densely connected subgraphs. The guiding principle is homophily—the tendency of nodes to connect with other, similar nodes. A community is therefore a set of nodes with many connections within the set and comparatively few connections to nodes outside the set.6 The question it answers is: "Which nodes are clustered together?" For example, in a scientific collaboration network, a community might represent a research lab where scientists frequently co-author papers with each other.Role Discovery, in contrast, is based on structural equivalence. It seeks to group nodes that have similar patterns of connectivity to other groups of nodes, regardless of whether they are themselves connected or even close to one another in the network. The question it answers is: "How are nodes connected to the rest of the network?" Nodes that fulfill the same role are structurally interchangeable.A canonical example illustrates this difference clearly: consider a network containing several distinct star-shaped clusters. The central node of each star cluster acts as a "hub." According to community detection, each star is a separate community. The hub of star A and the hub of star B belong to different communities. However, from a role discovery perspective, these two hubs perform the exact same function and have identical connectivity patterns relative to their respective peripheral nodes. Therefore, they belong to the same role (the "hub" role). Conversely, a hub node and a peripheral node within the same star belong to the same community but have vastly different roles.While traditionally viewed as orthogonal problems, research suggests that role discovery and community detection are complementary and can mutually enhance one another.6 Identifying roles can help refine community boundaries, and understanding community structure can provide context for the function of certain roles. For this project, treating them as separate, parallel tasks is a sound approach that allows for a focused investigation into each of these fundamental network properties.The following table provides a concise summary of the key differences:Table 1: Role Discovery vs. Community Detection| Feature | Role Discovery | Community Detection || :--- | :--- | :--- || Guiding Principle | Structural Equivalence | Homophily || Core Question | "How are nodes connected?" | "Which nodes are connected?" || Output | Groups of nodes with similar functions/positions | Densely connected clusters of nodes || Relationship to Proximity | Nodes in the same role can be far apart in the graph | Nodes in the same community must be close (densely interconnected) || Example | Hubs of different communities | Members of a single research group |1.3 A Typology of Common Network RolesThe roles discovered in a network are often given intuitive names that describe their structural function. Understanding this vocabulary is crucial for interpreting the output of role discovery algorithms. These roles are typically characterized by specific patterns in network centrality metrics and local connectivity.8Hubs / Cores: These are nodes of high importance and influence. Structurally, they are characterized by a high degree centrality (many direct connections) and often high eigenvector centrality (connected to other important nodes).8 Hubs act as local centers of activity and are often leaders or core members of groups. In the classic Zachary's Karate Club network, the instructor "Mr. Hi" and the club administrator "John A" are quintessential hubs, being the most connected individuals around whom the network's factions formed.10Bridges / Brokers: These nodes are critical for information flow across a network. Their defining characteristic is high betweenness centrality, meaning they lie on a large number of shortest paths between other pairs of nodes.8 They connect otherwise disconnected or distantly connected parts of the network, filling what are known as "structural holes".12 Removing a bridge node can often fragment a network or significantly increase path lengths between subgroups.Periphery Nodes: These nodes are located at the "edge" of the network. They typically have low degree and low centrality scores, with few connections to the rest of the graph.1 They represent members with marginal engagement or entities that are loosely affiliated with the main network structure.Liaisons, Gatekeepers, and Coordinators: These are more nuanced brokerage roles that consider the group affiliations of the connected nodes.8A Liaison connects two nodes from different groups, while not belonging to either group itself.A Gatekeeper controls the flow of information from an outside group to its own group.A Coordinator is a broker that connects nodes within its own group.Outliers: These are nodes with unusual or unique connectivity patterns that do not fit cleanly into any of the more common role categories.13 Identifying outliers can be important for tasks like anomaly or fraud detection.Part 2: A Tale of Two Methods: Traditional vs. GNN ApproachesThis section details the two distinct methodological approaches for the role discovery task: a traditional method based on explicit feature engineering and a modern deep learning method using Graph Neural Networks (GNNs). This structure directly aligns with the project requirements and facilitates a clear comparison between the two paradigms.2.1 Traditional Method: Role Discovery via Structural Feature EngineeringThe traditional approach to role discovery operationalizes the conceptual definitions from Part 1. If a role is defined by a node's structural properties, then one can identify roles by first measuring these properties and then grouping nodes that have similar measurements. This process can be broken down into two main steps: feature extraction and clustering.2.1.1 Step 1: Feature ExtractionThe first step is to create a numerical representation for each node that captures its structural characteristics. This is achieved by calculating a vector of node-level graph metrics. The resulting [num_nodes, num_features] matrix serves as the input for the subsequent clustering step. The NetworkX library is an excellent tool for this, as it provides efficient implementations of a wide range of graph algorithms.14A robust set of initial features should include:Centrality Measures: These quantify different facets of a node's importance.Degree Centrality: The number of connections a node has. For directed graphs, this splits into in-degree and out-degree.8Betweenness Centrality: Measures how often a node lies on the shortest path between other nodes, indicating a "broker" role.8Closeness Centrality: Measures the average farness (inverse of distance) to all other nodes, indicating nodes that can reach the rest of the network efficiently.9Eigenvector Centrality: Measures a node's influence based on being connected to other influential nodes.9Local Structure Measures: These describe the immediate neighborhood of a node.Clustering Coefficient: Measures the degree to which a node's neighbors are connected to each other. A high value suggests the node is part of a tightly-knit group.16Triangle Count: The number of triangles a node participates in, closely related to the clustering coefficient.15Advanced Structural Features: Graphlets: For a more powerful and nuanced feature set, one can move beyond simple metrics and use graphlets. Graphlets are small, connected, induced subgraphs (e.g., all non-isomorphic graphs with 3, 4, or 5 nodes).17 A node's feature vector can be defined by its graphlet degree vector, which counts how many times the node touches each type of graphlet at each unique position (automorphism orbit).18 This provides a rich, multi-dimensional signature of a node's local topological environment, capturing far more complex patterns than simple centrality measures.202.1.2 Step 2: Role Assignment via ClusteringOnce the node-feature matrix is constructed, the nodes are represented as points in a high-dimensional structural feature space. The task of assigning roles then becomes a standard clustering problem. A common and effective algorithm for this is K-Means. K-Means partitions the nodes into a pre-specified number of clusters, k, by minimizing the variance within each cluster. Nodes that are grouped into the same cluster are considered to have the same role. The number of roles, k, is a critical hyperparameter that must be determined as part of the experimental process.2.1.3 Context: The RolX AlgorithmWhile implementing a full feature-engineering-plus-clustering pipeline is a solid traditional approach, it is useful to understand the seminal RolX (Role eXtraction) algorithm, which represents a more sophisticated version of this idea.1 RolX consists of two main stages:ReFeX (Recursive Feature Extraction): Instead of using only basic local features, ReFeX generates a much richer feature set by recursively aggregating features from a node's neighborhood.5 For example, an initial feature is a node's degree. A recursive feature would be the mean and sum of its neighbors' degrees. This process is repeated for several iterations, creating features that describe progressively larger neighborhood structures.5Role Factorization via NMF: RolX takes the large, sparse node-feature matrix generated by ReFeX and applies Non-Negative Matrix Factorization (NMF). NMF decomposes the feature matrix V into two lower-rank, non-negative matrices: a node-role membership matrix G and a role-feature matrix F, such that V≈GF.2 The matrix G provides a "soft" or "mixed-membership" assignment, where each node has a distribution over the r discovered roles, which is more expressive than the "hard" assignment produced by K-Means.2.2 Deep Learning Method: Unsupervised GNNs for Role EmbeddingThe deep learning paradigm for role discovery shifts the burden from manual feature engineering to automatic representation learning.22 Instead of deciding which structural features are important, a Graph Neural Network (GNN) is trained to learn a low-dimensional vector representation, or embedding, for each node. The GNN acts as a powerful encoder that learns to distill a node's structural context into a dense vector. The underlying principle remains the same: nodes with similar structural roles should be mapped to nearby points in the embedding space.19 These embeddings can then be clustered to identify the roles.Since role discovery is an inherently unsupervised task (i.e., there are no ground-truth role labels to train on), the GNN must be trained using a self-supervised objective. Two prominent approaches are Graph Autoencoders and contrastive methods like Deep Graph Infomax.2.2.1 Method 1: Graph Autoencoder (GAE)A Graph Autoencoder is an unsupervised GNN framework that learns node embeddings by training the network to reconstruct the graph's structure.23 It comprises two main components 24:Encoder: This is a standard GNN model, such as a Graph Convolutional Network (GCN) or GraphSAGE, identical in architecture to those used for supervised tasks like link prediction. The encoder takes the graph's adjacency matrix A and node features X as input and produces a matrix of low-dimensional node embeddings Z. The formula is Z=GNN(X,A).Decoder: This is a function that takes the node embeddings Z and attempts to reconstruct the original adjacency matrix A. A simple and effective decoder is the inner product of node embeddings, followed by a sigmoid activation function to produce probabilities of edge existence: A^=σ(ZZT).25The GAE is trained by minimizing a reconstruction loss, typically the binary cross-entropy between the true adjacency matrix A and the reconstructed matrix A^.24 By forcing the model to compress the entire graph structure into the low-dimensional latent space Z and then decompress it, the embeddings in Z are compelled to capture the essential topological information for each node. These embeddings are therefore inherently rich in structural, role-defining information.2.2.2 Method 2: Deep Graph Infomax (DGI)An alternative and often more powerful self-supervised approach is Deep Graph Infomax (DGI).26 DGI is a contrastive method that learns node representations by maximizing the mutual information between the embedding of a node (a "local" representation) and a summary vector representing the entire graph (a "global" representation).26The DGI framework consists of:An Encoder (a GNN) that generates node embeddings H={h1​,h2​,...,hN​}.A Readout function (e.g., averaging all node embeddings) that creates a single graph summary vector s.A Discriminator that is trained to distinguish between "positive" pairs (hi​,s) (an embedding of a node from the original graph and the graph's summary) and "negative" pairs (h~j​,s) (an embedding of a node from a corrupted version of the graph and the original summary).26By training the encoder to produce node embeddings that the discriminator can easily associate with the correct global graph summary, DGI encourages the embeddings to capture features that are globally significant across the entire graph structure. This often leads to highly robust and informative representations for various downstream tasks, including clustering for role discovery.2.2.3 Final Step: ClusteringRegardless of whether a GAE or DGI is used to generate the node embedding matrix Z, the final step is identical to the traditional approach: a clustering algorithm like K-Means is applied to the rows of Z. Each resulting cluster corresponds to a discovered role.The following table summarizes the key differences between the traditional and GNN-based methodologies.Table 2: Comparison of Role Discovery Methodologies| Aspect | Traditional (Feature-based + Clustering) | GNN-based (Embedding + Clustering) || :--- | :--- | :--- || Feature Engineering | Manual & Explicit (e.g., calculating centrality) | Automatic & Implicit (Learned by the GNN) || Interpretability | High (Features are human-understandable, e.g., 'degree') | Low (Embeddings are dense, abstract vectors) || Performance | Strong baseline, but may miss complex, non-linear patterns | State-of-the-art, captures complex, high-order structures || Scalability | Feature calculation (e.g., betweenness) can be slow on large graphs | Can be more scalable with modern GNN sampling techniques || Implementation | NetworkX + scikit-learn | PyTorch Geometric + scikit-learn |The GNN-based approach represents a significant paradigm shift. The traditional method relies on a pre-defined set of features, embedding human assumptions about what constitutes a role directly into the model. In contrast, the GNN learns the features that are most salient for a high-level objective, such as graph reconstruction. This means the GNN may discover novel structural patterns not captured by standard metrics. A powerful analysis technique is to bridge this gap by interpreting the GNN-discovered roles through the lens of traditional features. For example, after clustering the GNN embeddings, one can calculate the average degree, betweenness, and clustering coefficient for the nodes in each role. This can reveal insights like "GNN-discovered role #3 corresponds to nodes with low degree but high betweenness centrality," making the abstract embeddings more interpretable.Part 3: Experimental Design and Evaluation FrameworkThis section outlines the practical components of the project: selecting appropriate datasets for experimentation and defining the metrics that will be used to evaluate and compare the performance of the different role discovery models.3.1 Dataset RecommendationsThe choice of dataset is critical for a meaningful exploration of role discovery. Unlike graph classification tasks that use collections of many small graphs, role discovery is best studied on a single, large, and structurally diverse graph. The dataset should ideally exhibit a variety of connectivity patterns that could give rise to distinct roles. The torch_geometric.datasets library provides several excellent candidates.30Recommendation 1: torch_geometric.datasets.Planetoid (Cora, CiteSeer, PubMed)Description: These are benchmark citation network datasets. Nodes represent academic publications and directed edges represent citations between them.31 The Cora dataset is a manageable and classic starting point.Suitability: Citation networks are well-known for their rich role structure. One can expect to find: (i) hub papers (e.g., survey articles that cite many papers), (ii) authority papers (e.g., foundational works that are cited by many), and (iii) peripheral or leaf-node papers (e.g., recent publications with few citations). This inherent structure makes them ideal for testing role discovery algorithms.Recommendation 2: torch_geometric.datasets.GNNBenchmarkDataset (with name='CLUSTER')Description: This is a large, synthetically generated graph designed specifically for clustering and community detection benchmarks.33 It contains a single graph with 12,000 nodes and well-defined ground-truth community structures.Suitability: While its primary design is for community detection, its size and complexity make it a challenging testbed for role discovery. More importantly, the presence of ground-truth community labels allows for a unique analysis: one can investigate the relationship between the discovered roles and the known communities. A successful role discovery algorithm should produce groupings that are largely orthogonal to the community structure, providing strong evidence that the model is capturing structural equivalence rather than just homophily.Recommendation 3: torch_geometric.datasets.ActorDescription: This is a dataset derived from Wikipedia, where nodes are film actors and edges connect actors who have appeared on the same page.Suitability: As a real-world social network, it is likely to contain a variety of interesting and interpretable roles. For example, one might discover roles corresponding to "blockbuster superstars" (hubs connected to many other actors), "character actors" (bridges who appear in diverse genres), and "niche actors" who work primarily within a specific sub-community.The following table summarizes these recommendations for practical use.Table 3: Recommended PyTorch Geometric Datasets for Role Discovery| Dataset Name | PyG Class | # Nodes | # Edges | Why It's Good for Role Discovery || :--- | :--- | :--- | :--- | :--- || Cora | Planetoid(name='Cora') | 2,708 | 5,429 | Classic benchmark; known to have hub/authority structures in citations. || CLUSTER | GNNBenchmarkDataset(name='CLUSTER') | 12,000 | 379,552 | Synthetic with known clusters; allows for comparing roles vs. communities. || Actor | Actor() | 7,600 | 33,544 | Real-world social network; likely to have diverse, interpretable roles. |3.2 Evaluation Metrics for Unsupervised Role DiscoveryEvaluating an unsupervised learning task like role discovery presents a unique challenge: there are typically no ground-truth labels against which to measure accuracy.34 Therefore, evaluation must rely on internal validation metrics. These metrics assess the quality of the resulting clusters (roles) based solely on the data itself, typically by measuring the compactness and separation of the clusters.35 These metrics are applied to the space in which the clustering was performed—either the hand-crafted structural feature space or the learned GNN embedding space.3.2.1 Internal Validation MetricsThe scikit-learn library provides standard implementations for several key internal validation metrics.Silhouette Score: This is one of the most popular and intuitive clustering metrics. For each data point (node), it calculates a score based on two values: a, the average distance to other points in its own cluster (measuring cohesion), and b, the average distance to points in the nearest neighboring cluster (measuring separation). The score for a single point is given by the formula s=(b−a)/max(a,b).37Interpretation: The score ranges from -1 to 1. A score near +1 is ideal, indicating that clusters are dense and well-separated. A score near 0 suggests overlapping clusters. A negative score indicates that points may have been assigned to the wrong cluster.37 The overall score is the average across all points.Davies-Bouldin Index (DBI): This metric is defined as the average similarity between each cluster and its most similar one, where similarity is a measure that compares the within-cluster distance to the between-cluster distance.Interpretation: Lower values of the DBI are better, with a score of 0 representing a perfect clustering where all clusters are maximally compact and separated.37Calinski-Harabasz Index (Variance Ratio Criterion): This index is calculated as the ratio of the between-cluster dispersion to the within-cluster dispersion.Interpretation: A higher Calinski-Harabasz score indicates better clustering performance, as it implies that the clusters are dense (low within-cluster dispersion) and well-separated (high between-cluster dispersion).353.2.2 Qualitative Evaluation via VisualizationQuantitative metrics, while useful, can sometimes be misleading, especially with complex cluster shapes.38 Therefore, it is crucial to supplement them with qualitative evaluation through visualization. This provides a powerful and intuitive sanity check on the quality of the learned representations.Method: The high-dimensional node feature vectors or embeddings must first be projected into a 2D space suitable for plotting. The most common and effective techniques for this are t-SNE (t-Distributed Stochastic Neighbor Embedding) and UMAP (Uniform Manifold Approximation and Projection). After projection, a scatter plot is created where each point represents a node, and the color of the point is determined by its assigned role (its cluster ID).Interpretation: An effective role discovery model should produce embeddings that are separable. In the 2D visualization, this will manifest as distinct, well-defined "islands" of color, where each island corresponds to a different role.39 Overlapping or poorly defined clusters in the plot suggest that the model is struggling to learn discriminative representations.The following table provides a practical summary of the recommended evaluation metrics.Table 4: Unsupervised Clustering Evaluation Metrics| Metric | Interpretation | scikit-learn function || :--- | :--- | :--- || Silhouette Score | Higher is better (range [-1, 1]) | sklearn.metrics.silhouette_score || Davies-Bouldin Index | Lower is better (range This transforms hyperparameter selection from a guess into a systematic, data-driven experiment.Part 4: Actionable Code Scaffolding for Role DiscoveryThis section provides the Python code skeletons necessary to begin the implementation phase of the project. The file structure is designed to be parallel to the existing link prediction architecture, ensuring modularity, reusability, and straightforward integration into the final project. Each script includes detailed comments explaining its purpose, the logic of its components, and its connection to the theoretical concepts discussed in the preceding sections.4.1 Main Experiment Runner: project/role_discovery/RoleDiscoveryExperiment.pyThis script serves as the main entry point for conducting role discovery experiments. It orchestrates the entire process, from loading data and instantiating models to running the evaluation and saving the results. Its design supports systematic experimentation, particularly for tuning the number of roles, k.Python# project/role_discovery/RoleDiscoveryExperiment.py

Conclusions and RecommendationsThis comprehensive study provides a complete roadmap for tackling the role discovery component of the network science project. By understanding the foundational concepts, implementing both traditional and GNN-based methods, and applying a rigorous evaluation framework, a high-quality and insightful analysis can be achieved.Key Conceptual Takeaways:Role Discovery is distinct from Community Detection: The former is driven by structural equivalence (functional similarity), while the latter is driven by homophily (dense connectivity). This distinction is central to the project and must be clearly articulated.Roles are defined by structural patterns: Traditional methods make this explicit by engineering features based on graph metrics. GNNs make this implicit by learning features that are salient for a self-supervised task.Methodological Recommendations:Start with the Traditional Method: The FeatureBasedRoles model is simpler to implement and provides a crucial baseline. It relies on well-understood libraries (NetworkX, scikit-learn) and produces interpretable features. This will help build intuition about the dataset's structure.Implement the GNN Method: The GCNEmbedder using a Graph Autoencoder is a strong and representative deep learning approach. It directly parallels the GNN architectures used in the link prediction task, ensuring consistency. The provided code offers a solid foundation for the self-supervised training loop.Systematically Tune k: The number of roles, k, is the most important hyperparameter. The RoleDiscoveryExperiment.py script is designed to loop over a range of k values. Plotting the Silhouette Score against k for both models will be a key result, providing a data-driven justification for the chosen number of roles for the final analysis.Evaluation and Analysis Plan:Use the Silhouette Score as the primary quantitative metric for comparing the clustering quality of the two methods across different values of k.Supplement this with the Davies-Bouldin and Calinski-Harabasz indices for a more robust evaluation.Crucially, generate and analyze the t-SNE visualizations. These plots provide an indispensable qualitative check on whether the learned representations are genuinely separable into distinct roles.For the final report, move beyond just comparing scores. Interpret the discovered roles. For a given clustering result (e.g., the one for the optimal k), analyze the characteristics of the nodes in each role. For instance, calculate the average degree, betweenness, and clustering coefficient for each role. This will help assign meaningful labels (e.g., "hub," "bridge," "periphery") to the discovered groups and provides a deep comparison between what the traditional features capture explicitly and what the GNN learns implicitly.By following this structured plan, the role discovery task can be executed efficiently and effectively, resulting in a comprehensive and insightful contribution to the overall group project.